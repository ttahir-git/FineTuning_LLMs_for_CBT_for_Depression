{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce9205e-db91-4acb-a344-30758482c4db",
   "metadata": {
    "id": "2ce9205e-db91-4acb-a344-30758482c4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping llama-cpp-python as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.24.1)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.2)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m268.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.1-cp310-cp310-linux_x86_64.whl size=94101464 sha256=3bf570a995389cab54c53742a6b01f80b4e81068246f8c50e6cc15b1b10ceed0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z12qc3tw/wheels/f8/b0/a2/f47d952aec7ab061b9e2a345e23a1e1e137beb7891259e3d0c\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, diskcache, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.1 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting openai\n",
      "  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading openai-1.53.0-py3-none-any.whl (387 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, pydantic-core, jiter, h11, annotated-types, pydantic, httpcore, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.7.0 openai-1.53.0 pydantic-2.9.2 pydantic-core-2.23.4 tqdm-4.66.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting tenacity\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting huggingface_hub[cli]\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub[cli])\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.12.2)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.39)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2022.12.7)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.9)\n",
      "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: pfzy, fsspec, InquirerPy, huggingface_hub\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed InquirerPy-0.3.4 fsspec-2024.10.0 huggingface_hub-0.26.2 pfzy-0.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m161.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m152.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DGGML_CUDA=on -DCMAKE_CUDA_ARCHITECTURES=86\" pip install llama-cpp-python --no-cache-dir\n",
    "!pip install openai\n",
    "!pip install tenacity\n",
    "!pip install -U \"huggingface_hub[cli]\"\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NRGfFRUKjel7",
   "metadata": {
    "id": "NRGfFRUKjel7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c27addce6a24fd6b22678d8e2231655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mistral-7B-Instruct-v0.3-Q8_0.gguf:   0%|          | 0.00/7.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type\n",
    "import re\n",
    "from os import getenv\n",
    "from llama_cpp import Llama\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from threading import Lock\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "log_directory = \"logs\"\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "log_file = os.path.join(log_directory, f\"cbt_simulation_base_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_log_file = os.path.join(log_directory, f\"responses_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "\n",
    "STOP_TOKENS = [\n",
    "    \"### Instruction:\",\n",
    "    \"### Response:\",\n",
    "    \"Patient:\",\n",
    "    \"? Patient:\",\n",
    "    \"?\\n\\n### Patient:\",\n",
    "    \"### Patient:\",\n",
    "    \"\\nPatient:\",\n",
    "    \"\\n### Response:\",\n",
    "    \"?\\nPatient:\",\n",
    "    \"situations\\nPatient:\",\n",
    "    \"\\n\\nPatient:\",\n",
    "    \"?\\n\\nPatient:\",\n",
    "    \".\\nPatient:\",\n",
    "    \"\\n\\n### Response:\",\n",
    "    \".Patient:\",\n",
    "    \"\\n\\n### Patient:\",\n",
    "    \"\\nTherapist:\",\n",
    "    \"\\n\\n### Patient:\\n\"\n",
    "]\n",
    "\n",
    "patient_profiles = [\n",
    "    {\n",
    "        \"name\": \"Alicia Rodriguez\",\n",
    "        \"age\": \"28\",\n",
    "        \"gender\": \"Female\",\n",
    "        \"ethnicity\": \"Hispanic\",\n",
    "        \"education\": \"Master's Degree\",\n",
    "        \"occupation\": \"Software Developer\",\n",
    "        \"symptom_severity\": \"Moderate\",\n",
    "        \"engagement_level\": \"Medium\",\n",
    "        \"life_events\": [\"Recent job promotion\", \"Death of a loved one\", \"Moving to a new city\"],\n",
    "        \"family_background\": \"First-generation immigrant\",\n",
    "        \"hobbies_interests\": [\"Coding\", \"Salsa dancing\", \"Reading sci-fi novels\"],\n",
    "        \"social_support\": \"Limited social connections\",\n",
    "        \"personality_traits\": [\"Perfectionist\", \"Introverted\", \"Analytical\"],\n",
    "        \"coping_mechanisms\": [\"Overworking\", \"Problem-solving\", \"Social withdrawal\"],\n",
    "        \"background\": \"Alicia is a first-generation Hispanic American, born to parents who immigrated from Mexico when she was just two years old. Growing up in a close-knit community in East Los Angeles, she excelled academically, driven by her parents' emphasis on education as a path to success. Alicia's passion for technology led her to pursue a computer science degree, graduating summa cum laude from UCLA before earning her Master's from Stanford. Now working as a software developer at TechNova, a rapidly growing AI startup in San Francisco, Alicia has recently been promoted to team lead. This promotion, while a significant achievement, has intensified her struggle with imposter syndrome. As one of the few women, and even fewer Latinas, in a leadership position, she feels constant pressure to prove her worth and justify her rapid rise within the company.The unexpected loss of her grandmother, Maria, three months ago has profoundly affected Alicia. Maria, who helped raise her while her parents worked multiple jobs, was Alicia's primary source of emotional support and connection to her cultural roots. This loss has left Alicia feeling unmoored and intensely lonely in a city where she's lived for only a year and has yet to form deep friendships. Alicia's perfectionistic tendencies, instilled by the high expectations of her immigrant parents and reinforced by her competitive academic and professional environments, have made it difficult for her to acknowledge her emotional struggles or seek help. She often works 12-hour days, taking on additional projects and staying late to review her team's code, using work as a distraction from her grief and anxiety. Her depression manifests in various ways: persistent fatigue that coffee can't seem to cure, difficulty concentrating during important meetings, and a pervasive sense of worthlessness that contradicts her impressive resume. Alicia finds herself withdrawing from the few social connections she has, canceling salsa classes and declining invitations from coworkers. At night, she often loses herself in complex coding projects or science fiction novels, temporary escapes that ultimately reinforce her isolation. Despite outward appearances of success, Alicia's internal struggle is taking a toll. She's experiencing frequent headaches, disrupted sleep patterns, and has started to make uncharacteristic errors in her work. The contrast between her professional achievements and her emotional turmoil has left Alicia feeling increasingly disconnected from herself and unsure of her future path.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Marcus Thompson\",\n",
    "        \"age\": \"42\",\n",
    "        \"gender\": \"Male\",\n",
    "        \"ethnicity\": \"African American\",\n",
    "        \"education\": \"Master's Degree\",\n",
    "        \"occupation\": \"High School Teacher\",\n",
    "        \"symptom_severity\": \"Moderate to Severe\",\n",
    "        \"engagement_level\": \"High\",\n",
    "        \"life_events\": [\"Divorce\", \"Career change\", \"Caring for an ill family member\"],\n",
    "        \"family_background\": \"Single-parent household\",\n",
    "        \"hobbies_interests\": [\"Community activism\", \"Jazz music\", \"Basketball\", \"Reading historical biographies\"],\n",
    "        \"social_support\": \"Active in community groups\",\n",
    "        \"personality_traits\": [\"Empathetic\", \"Ambitious\", \"Sensitive\"],\n",
    "        \"coping_mechanisms\": [\"Exercise\", \"Helping others\", \"Occasional stress eating\"],\n",
    "        \"background\": \"Marcus is a 42-year-old African American high school history teacher and community activist in inner-city Chicago. He's been teaching at Lincoln Park High School for the past 15 years, where he's known for his engaging lessons on civil rights and social movements. Marcus is deeply passionate about education and social justice, often organizing after-school programs and weekend workshops to help at-risk students. However, he's increasingly overwhelmed by the systemic issues affecting his students, such as poverty, gang violence, and lack of resources. Three years ago, Marcus went through a difficult divorce from his wife of 12 years, Sarah. They have two children: Jamal (10) and Aisha (8). The divorce was primarily due to growing apart and communication breakdown, exacerbated by Marcus's long work hours and community commitments. He's now learning to co-parent while dealing with significant financial pressures, including alimony payments and the cost of maintaining two households. Adding to his stress, Marcus's mother, Gloria (68), was recently diagnosed with early-stage Alzheimer's. As an only child from a single-parent household, Marcus feels a strong responsibility to care for her, often spending weekends at her home in the suburbs, which further strains his time and emotions. Marcus's depression manifests as irritability, difficulty concentrating during lesson planning, and persistent feelings of guilt about not being able to do more for his students, children, and mother. He often lies awake at night, ruminating on perceived failures and the overwhelming challenges faced by his community. Growing up in the Englewood neighborhood with a single mother who worked multiple jobs, Marcus developed a strong work ethic and determination to succeed. He was the first in his family to attend college, earning a scholarship to Northwestern University where he completed both his bachelor's and master's degrees in Education and African American Studies. This background fuels his determination to be present for his own children despite the challenges of co-parenting and his busy schedule. To cope with his depression, Marcus tries to maintain a rigorous exercise routine, including early morning runs along Lake Michigan and weekend basketball games with a local community league. He's also heavily involved in his local church, leading youth mentorship programs. However, he often finds himself stress eating late at night, particularly favoring his mother's recipe for sweet potato pie, which brings both comfort and guilt. Marcus's high engagement in therapy is driven by his desire to be a positive role model for both his children and students. He's aware of the stigma surrounding mental health in his community and hopes that by addressing his own struggles, he can encourage others to seek help. Despite his challenges, Marcus remains committed to making a difference in his community, embodying the change he wishes to see in the world.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Samantha Chen\",\n",
    "        \"age\": \"35\",\n",
    "        \"gender\": \"Female\",\n",
    "        \"ethnicity\": \"East Asian\",\n",
    "        \"education\": \"Bachelor's Degree\",\n",
    "        \"occupation\": \"Entrepreneur\",\n",
    "        \"symptom_severity\": \"Moderate\",\n",
    "        \"engagement_level\": \"Medium\",\n",
    "        \"life_events\": [\"Career change\", \"Financial difficulties\", \"Identity crisis\"],\n",
    "        \"family_background\": \"High-achieving family with pressure to succeed\",\n",
    "        \"hobbies_interests\": [\"Sustainable fashion design\", \"Yoga\", \"Organic gardening\"],\n",
    "        \"social_support\": \"Supportive partner, strained family relationships\",\n",
    "        \"personality_traits\": [\"Creative\", \"Anxious\", \"Perfectionist\"],\n",
    "        \"coping_mechanisms\": [\"Mindfulness meditation\", \"Journaling\", \"Emotional eating\"],\n",
    "        \"background\": \"Samantha is a second-generation Chinese American born and raised in San Francisco. Her parents immigrated from Guangzhou, China in the 1980s and worked tirelessly to establish a successful import-export business. Growing up, Samantha excelled academically, graduating as valedictorian from her high school and earning a degree in Business Administration from UC Berkeley. For the past decade, Samantha climbed the corporate ladder at a prestigious tech company, reaching a senior management position by age 32. However, she increasingly felt unfulfilled and at odds with the company's environmental practices. After months of internal struggle and heated discussions with her parents, Samantha quit her job to launch 'GreenThread', an eco-friendly clothing line. While passionate about her new venture, Samantha grapples with severe anxiety about the business's uncertain future. She's invested a significant portion of her savings and taken out loans, adding financial stress to her already fragile mental state. The guilt of disappointing her parents, who view her career change as reckless and ungrateful, weighs heavily on her. Their relationship has become strained, with tense weekly family dinners and frequent arguments about her choices. Samantha's depression manifests as chronic insomnia, often lying awake until 3 or 4 AM, ruminating over business decisions and family conflicts. She's lost 15 pounds in the past three months due to a near-complete loss of appetite, surviving mostly on coffee and occasional meal replacement shakes. Once outgoing, she now frequently cancels plans with friends and has stopped attending her weekly book club. Her marriage to Michael, a supportive software engineer, is showing signs of strain. While he tries to be understanding, he's frustrated by Samantha's emotional distance and her refusal to seek professional help until now. They haven't been intimate in months, and their communication has devolved into brief, practical exchanges about household matters. Samantha's perfectionism, once an asset in her corporate career, now paralyzes her with indecision in her new role as an entrepreneur. She obsesses over every detail of her clothing designs and business plan, often redoing work multiple times and missing deadlines. While she attempts to cope through daily meditation and journaling, Samantha often finds herself binge-eating late at night, particularly favoring sugary cereals and ice cream - comfort foods from her childhood. She feels shame about this behavior, seeing it as a personal failure and further proof of her inability to control her life. Samantha's engagement in therapy is inconsistent. Some sessions she's fully present and eager to work on herself, while in others she's distant and defensive, especially when discussing her family or the possibility of medication. Her reluctance partly stems from the stigma around mental health in her community, where seeking therapy is often seen as a sign of weakness or failure.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Derek Olsen\",\n",
    "        \"age\": \"55\",\n",
    "        \"gender\": \"Male\",\n",
    "        \"ethnicity\": \"Caucasian\",\n",
    "        \"education\": \"High School\",\n",
    "        \"occupation\": \"Unemployed (Former Construction Worker)\",\n",
    "        \"symptom_severity\": \"Severe\",\n",
    "        \"engagement_level\": \"Low\",\n",
    "        \"life_events\": [\"Chronic illness diagnosis\", \"Job loss\", \"Financial difficulties\"],\n",
    "        \"family_background\": \"Blue-collar family with history of substance abuse\",\n",
    "        \"hobbies_interests\": [\"Woodworking\", \"Fishing\", \"Watching sports\"],\n",
    "        \"social_support\": \"Estranged from family\",\n",
    "        \"personality_traits\": [\"Reserved\", \"Pessimistic\", \"Resilient\"],\n",
    "        \"coping_mechanisms\": [\"Substance use\", \"Social withdrawal\", \"Anger or aggression\"],\n",
    "        \"background\": \"Derek Olsen is a 55-year-old Caucasian male who spent 30 years as a skilled construction worker, specializing in commercial building projects. His career came to an abrupt halt three years ago when he suffered a severe back injury on a job site, resulting in multiple herniated discs and chronic, debilitating pain. The injury forced him onto disability, a transition he's struggled to accept. Growing up in a blue-collar family in a small Midwest town, Derek was the middle child of five. His father, a factory worker, battled alcoholism, while his mother worked part-time as a waitress to make ends meet. This upbringing instilled in Derek a strong work ethic but also normalized substance use as a coping mechanism. He dropped out of high school in his junior year to start working full-time in construction, eventually earning his GED at 28. Derek married his high school sweetheart, Sarah, at 22, and they had two children: Emma (now 30) and Jake (now 27). The marriage ended in divorce after 15 years, largely due to Derek's workaholic tendencies and growing alcohol dependency. Post-divorce, Derek maintained a close relationship with his children until his injury, when his depression and substance abuse worsened, causing a rift. The chronic pain from his injury is a constant in Derek's life, affecting his sleep, mood, and ability to perform even simple tasks. He's been prescribed various pain medications, which he sometimes misuses to cope with both physical and emotional pain. The loss of his career has hit Derek hard financially and emotionally. Once the breadwinner and a respected craftsman, he now struggles with feelings of worthlessness and a loss of identity. Derek's depression manifests in prolonged periods of isolation, where he can go days without leaving his small, cluttered apartment. He's lost interest in his former hobbies of woodworking and fishing, with his tools and fishing gear gathering dust in the garage. His social circle, once comprised of coworkers and drinking buddies, has dwindled to almost nothing. He spends most days watching TV, particularly sports, which serves as his primary connection to the outside world. Financially, Derek is barely staying afloat on disability payments and occasional under-the-table odd jobs. The stress of potential eviction and mounting medical bills exacerbates his mental state. He's behind on child support payments, which further strains his relationship with his children. Derek's resistance to therapy stems from a deeply ingrained belief that men should be self-reliant and that seeking help is a sign of weakness. This attitude, combined with his skepticism about mental health treatment, makes engaging in therapy challenging. When he does attend sessions, he's often guarded, deflecting with sarcasm or responding with minimal information. Despite his gruff exterior, Derek harbors deep-seated feelings of guilt and shame about his current situation and how it's affected his relationship with his children. He occasionally experiences passive suicidal ideation, though he's never made a plan or attempt. His resilience, a trait that served him well in his physically demanding career, now manifests as a stubborn determination to handle his problems on his own, even as evidence mounts that this approach isn't working.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Naomi Patel\",\n",
    "        \"age\": \"23\",\n",
    "        \"gender\": \"Non-binary\",\n",
    "        \"ethnicity\": \"South Asian\",\n",
    "        \"education\": \"Some College\",\n",
    "        \"occupation\": \"Graduate Student\",\n",
    "        \"symptom_severity\": \"Moderate to Severe\",\n",
    "        \"engagement_level\": \"High\",\n",
    "        \"life_events\": [\"Coming out as LGBTQ+\", \"Moving to a new city\", \"Academic struggles\"],\n",
    "        \"family_background\": \"Conservative immigrant family\",\n",
    "        \"hobbies_interests\": [\"Environmental activism\", \"Poetry writing\", \"Indie music\", \"Vegetarian cooking\"],\n",
    "        \"social_support\": \"LGBTQ+ support network\",\n",
    "        \"personality_traits\": [\"Sensitive\", \"Ambitious\", \"Creative\"],\n",
    "        \"coping_mechanisms\": [\"Journaling\", \"Seeking social support\", \"Occasional self-harm\"],\n",
    "        \"background\": \"Naomi is a 23-year-old South Asian American graduate student pursuing a Master's degree in Environmental Science at UC Berkeley. Born and raised in a small town in New Jersey, they moved to California for their studies, marking their first time living away from their close-knit family. Naomi's parents immigrated from Gujarat, India in the late 1990s and have instilled strong cultural values and high academic expectations in their children. Growing up, Naomi excelled academically, graduating as valedictorian from their high school. However, they've always felt a disconnect between their internal identity and the external expectations placed upon them. This internal struggle intensified during their undergraduate years at Rutgers University, where they first encountered concepts of gender fluidity and non-binary identities. Naomi's decision to come out as non-binary six months ago has been met with mixed reactions. While their younger sister has been supportive, their parents struggle to understand, often still using feminine pronouns and expressing disappointment about Naomi's choice to cut their hair short and adopt a more androgynous style. This family tension has exacerbated Naomi's feelings of isolation and self-doubt. In their graduate program, Naomi is passionate about researching the impact of climate change on coastal communities, inspired by their family's roots in Gujarat's coastal region. However, the rigorous academic environment, combined with being in a new city and navigating their identity, has led to increased stress and depressive symptoms. Naomi often finds themselves overwhelmed by deadlines, experiencing chronic fatigue, and struggling to concentrate during lectures and while writing papers. Naomi has found some solace in Berkeley's vibrant LGBTQ+ community, attending support group meetings and participating in climate change protests. They've also started exploring vegetarian cooking as a way to connect with their cultural roots while aligning with their environmental values. Despite these positive outlets, Naomi has resorted to self-harm on three occasions in the past two months when feeling particularly overwhelmed. Recognizing the need for professional help, Naomi has sought therapy, showing high engagement in sessions. They're motivated to develop healthier coping mechanisms, build resilience, and find ways to bridge the gap between their identity and cultural background. Naomi hopes that through therapy, they can improve their academic performance, strengthen their relationships, and cultivate a stronger sense of self-acceptance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class RateLimiter:\n",
    "    \"\"\"\n",
    "    Manages the rate of requests to ensure compliance with rate limits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, requests_per_minute=20):\n",
    "        self.requests_per_minute = requests_per_minute\n",
    "        self.interval = 60.0 / requests_per_minute\n",
    "        self.last_request = time.time()\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def wait(self):\n",
    "        \"\"\"\n",
    "        Waits for the appropriate interval before allowing the next request.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            current_time = time.time()\n",
    "            time_since_last = current_time - self.last_request\n",
    "            if time_since_last < self.interval:\n",
    "                time.sleep(self.interval - time_since_last)\n",
    "            self.last_request = time.time()\n",
    "\n",
    "rate_limiter = RateLimiter(requests_per_minute=20)\n",
    "\n",
    "openrouter_client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"***\",\n",
    ")\n",
    "\n",
    "def log_response(speaker, response):\n",
    "    \"\"\"\n",
    "    Logs each response to a separate file with a timestamp and speaker identifier.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(response_log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            f.write(f\"\\n[{timestamp}] {speaker}:\\n{response}\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "    except IOError as e:\n",
    "        logging.error(f\"Error writing to response log: {e}\")\n",
    "\n",
    "def verify_gpu_setup():\n",
    "    \"\"\"\n",
    "    Verifies the GPU setup and prints diagnostic information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Current GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"GPU Memory Usage:\")\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated(0)//1024**2}MB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved(0)//1024**2}MB\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not available\")\n",
    "\n",
    "    test_prompt = \"This is a test.\"\n",
    "    start_time = time.time()\n",
    "    for model in models:\n",
    "        response = model(test_prompt, max_tokens=10)\n",
    "    end_time = time.time()\n",
    "    print(f\"Test inference time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Counts the number of words in the provided text.\n",
    "    \"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "def detect_session_end(text):\n",
    "    \"\"\"\n",
    "    Determines if the given text contains phrases indicating the end of a therapy session.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, str]: A boolean indicating if the end was detected and the phrase that was found.\n",
    "    \"\"\"\n",
    "    goodbye_phrases = [\n",
    "        r\"\\bgoodbye\\b\",\n",
    "        r\"\\bbye\\b\",\n",
    "        r\"\\bsee you next time\\b\",\n",
    "        r\"\\buntil our next session\\b\",\n",
    "        r\"\\bthat's all for today\\b\",\n",
    "        r\"\\bwe're out of time\\b\",\n",
    "        r\"\\bsee you next week\\b\",\n",
    "        r\"\\btake care\\b\",\n",
    "        r\"\\bhave a good week\\b\",\n",
    "        r\"\\bmain topics discussed\\b\",\n",
    "        r\"\\bmain points discussed\\b\",\n",
    "        r\"\\bour time is up\\b\",\n",
    "        r\"\\buntil next time\\b\",\n",
    "        r\"\\bsee you soon\\b\",\n",
    "        r\"\\bI'll see you at our next appointment\\b\",\n",
    "        r\"\\bdon't hesitate to reach out\\b\"\n",
    "    ]\n",
    "\n",
    "    for phrase in goodbye_phrases:\n",
    "        if re.search(phrase, text, re.IGNORECASE):\n",
    "            return True, phrase\n",
    "\n",
    "    return False, \"\"\n",
    "\n",
    "def retry_with_validation(func):\n",
    "    \"\"\"\n",
    "    Decorator that applies retry logic with validation checks to the decorated function.\n",
    "    \"\"\"\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(10),\n",
    "        wait=wait_random_exponential(min=1, max=60),\n",
    "        retry=retry_if_exception_type((Exception, ValueError))\n",
    "    )\n",
    "    def wrapper(*args, **kwargs):\n",
    "        rate_limiter.wait()\n",
    "        response = func(*args, **kwargs)\n",
    "\n",
    "        if response is None:\n",
    "            raise ValueError(\"Null response received\")\n",
    "\n",
    "        cleaned_response = response.strip()\n",
    "\n",
    "        invalid_responses = ['', '.', '\\n', ' ', '...']\n",
    "        if cleaned_response in invalid_responses:\n",
    "            logging.warning(f\"Invalid response detected: '{cleaned_response}'\")\n",
    "            raise ValueError(f\"Invalid response detected: '{cleaned_response}'\")\n",
    "\n",
    "        if len(cleaned_response.split()) < 2:\n",
    "            logging.warning(f\"Response too short: '{cleaned_response}'\")\n",
    "            raise ValueError(f\"Response too short: '{cleaned_response}'\")\n",
    "\n",
    "        return response\n",
    "    return wrapper\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_random_exponential(min=1, max=60),\n",
    "    retry=retry_if_exception_type((Exception, ValueError))\n",
    ")\n",
    "def get_cbt_response(conversation_history, model):\n",
    "    \"\"\"\n",
    "    Generates a CBT therapist response based on the conversation history.\n",
    "\n",
    "    Args:\n",
    "        conversation_history (list): The history of the conversation.\n",
    "        model: The language model to generate responses.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated therapist response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        instruction = \"You are an AI CBT therapist. Respond appropriately in the following conversation:\"\n",
    "\n",
    "        conversation_text = []\n",
    "        for msg in conversation_history:\n",
    "            speaker = \"Patient\" if msg[\"role\"] == \"user\" else \"Therapist\"\n",
    "            content = msg[\"content\"].strip()\n",
    "            conversation_text.append(f\"{speaker}: {content}\")\n",
    "\n",
    "        prompt = f\"{instruction} [INST]{chr(10).join(conversation_text)}[/INST]\"\n",
    "\n",
    "        generated = model(\n",
    "            prompt=prompt,\n",
    "            max_tokens=600,\n",
    "            stop=STOP_TOKENS\n",
    "        )\n",
    "\n",
    "        if generated is None or 'choices' not in generated or not generated['choices']:\n",
    "            raise ValueError(\"Empty response from model\")\n",
    "\n",
    "        generated_response = generated['choices'][0]['text'].strip()\n",
    "\n",
    "        if not generated_response or generated_response in ['.', '...', '\\n', ' ']:\n",
    "            raise ValueError(f\"Invalid response generated: '{generated_response}'\")\n",
    "\n",
    "        cleaned_response = re.sub(r\"^(Therapist:?\\s*)\", \"\", generated_response)\n",
    "\n",
    "        if not cleaned_response.endswith(('.', '!', '?')):\n",
    "            cleaned_response += '.'\n",
    "\n",
    "        if len(cleaned_response.split()) < 3:\n",
    "            raise ValueError(\"Response too short\")\n",
    "\n",
    "        log_response(\"Therapist\", cleaned_response)\n",
    "        return cleaned_response\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating CBT response: {e}\")\n",
    "        raise\n",
    "\n",
    "@retry_with_validation\n",
    "def generate_patient_response(conversation_history, patient_profile, session_number, previous_summary, is_first_message=False, model_index=0):\n",
    "    \"\"\"\n",
    "    Generates a patient response with enhanced validation based on the conversation history and patient profile.\n",
    "\n",
    "    Args:\n",
    "        conversation_history (list): The history of the conversation.\n",
    "        patient_profile (dict): The profile of the patient.\n",
    "        session_number (int): The current session number.\n",
    "        previous_summary (str): Summary of the previous session.\n",
    "        is_first_message (bool): Indicates if it's the first message of the session.\n",
    "        model_index (int): Index of the model to use.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated patient response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        system_message = (\n",
    "            f\"You are roleplaying as a patient named {patient_profile['name']} in a text-based CBT session with an AI therapist named Nova. \"\n",
    "            f\"Your detailed profile: {patient_profile}. \"\n",
    "            f\"This is session number {session_number}. \"\n",
    "            f\"Respond in character based on your profile, adopting speech patterns and vocabulary appropriate for your age, background, and personality traits. Most importantly be SPECIFIC and detailed with your responses and interaction. Don't be vague and generic. Make your story and responses lifelike and realistic. \"\n",
    "            f\"Keep your responses short, ideally 1-5 sentences. \"\n",
    "            f\"You are not psychologically minded and may need extra explanation to understand CBT concepts. Don't be afraid to ask for clarification and more details. If you need an example to understand please ask. Let the therapist lead the session, put the onus on them. \"\n",
    "            f\"If the therapist mentions something about you that is incorrect, that you haven't told them or that doesn't align with your experience, you should correct them. Your therapist is a LLM so they can hallucinate, be very watchful for instances where the therapist references things that did not happen and always point them out. \"\n",
    "            f\"Use the summary of the previous session to inform your responses in the current session. \"\n",
    "            f\"AVOID REPETITION in your responses. \"\n",
    "            f\"When the therapist says something, you don't have to respond to every detail they mentioned. It's okay to respond to only one or two things in therapist's message because real people don't programmatically respond to every aspect of a statement. \"\n",
    "        )\n",
    "\n",
    "\n",
    "        if is_first_message:\n",
    "            if previous_summary:\n",
    "                initial_message = f\"Hi, I'm {patient_profile['name']}. This is my {session_number} CBT session. Last time we talked about: {previous_summary}\"\n",
    "            else:\n",
    "                initial_message = f\"Hi, I'm {patient_profile['name']}. This is my first CBT session. I'm here because I've been feeling down lately.\"\n",
    "\n",
    "            return initial_message\n",
    "\n",
    "        messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "        relevant_history = conversation_history[-10:]\n",
    "        for message in relevant_history:\n",
    "            role = \"assistant\" if message[\"role\"] == \"user\" else \"user\"\n",
    "            messages.append({\"role\": role, \"content\": message[\"content\"]})\n",
    "\n",
    "        response = openrouter_client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-chat\",\n",
    "            messages=messages,\n",
    "            max_tokens=300,\n",
    "            temperature=1\n",
    "        )\n",
    "\n",
    "        generated_response = response.choices[0].message.content.strip()\n",
    "\n",
    "        if not generated_response or generated_response in ['.', '...', '\\n', ' ']:\n",
    "            raise ValueError(f\"Invalid patient response generated: '{generated_response}'\")\n",
    "\n",
    "        cleaned_response = re.sub(r\"^(Patient:?\\s*)\", \"\", generated_response)\n",
    "\n",
    "        if len(cleaned_response.split()) < 3:\n",
    "            raise ValueError(\"Patient response too short\")\n",
    "\n",
    "        log_response(\"Patient\", cleaned_response)\n",
    "        return cleaned_response\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating patient response: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_response_quality(response):\n",
    "    \"\"\"\n",
    "    Validates the quality of a response based on specific criteria.\n",
    "\n",
    "    Args:\n",
    "        response (str): The response text to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the response meets quality criteria, False otherwise.\n",
    "    \"\"\"\n",
    "    if not response:\n",
    "        return False\n",
    "\n",
    "    cleaned = response.strip()\n",
    "\n",
    "    if len(cleaned.split()) < 3:\n",
    "        return False\n",
    "\n",
    "    if cleaned in ['.', '...', '\\n', ' ']:\n",
    "        return False\n",
    "\n",
    "    has_structure = any(char in cleaned for char in '.!?')\n",
    "    if not has_structure:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "@retry_with_validation\n",
    "def generate_session_summary(conversation_history, patient_profile, session_number):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive summary of the therapy session.\n",
    "\n",
    "    Args:\n",
    "        conversation_history (list): The history of the conversation.\n",
    "        patient_profile (dict): The profile of the patient.\n",
    "        session_number (int): The current session number.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated session summary.\n",
    "    \"\"\"\n",
    "    system_message = (\n",
    "        f\"Concisely summarize the key points of the therapy session focusing on the following aspects:\\n\"\n",
    "        \"1. Main topics discussed\\n\"\n",
    "        \"2. Techniques or exercises that were introduced or practiced\\n\"\n",
    "        \"3. Things that appeared helpful or important\\n\"\n",
    "        \"4. Any homework or tasks assigned\\n\"\n",
    "        \"5. Any insights or realizations that appeared during the session\\n\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"Session number: {session_number}\\nFull conversation history:\\n\" +\n",
    "         \"\\n\".join([f\"{'Me' if msg['role'] == 'user' else 'Therapist'}: {msg['content']}\"\n",
    "                   for msg in conversation_history])}\n",
    "    ]\n",
    "\n",
    "    max_attempts = 10\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            completion = openrouter_client.chat.completions.create(\n",
    "                model=\"anthropic/claude-3.5-sonnet\",\n",
    "                messages=messages,\n",
    "                temperature=0.3,\n",
    "            )\n",
    "            summary = completion.choices[0].message.content.strip()\n",
    "\n",
    "            word_count = len(summary.split())\n",
    "            if summary and not summary.isspace() and summary != '.' and word_count >= 80:\n",
    "                return \"Session Summary:\\n\\n\" + summary\n",
    "            else:\n",
    "                if attempt == max_attempts - 1:\n",
    "                    fallback_summary = (\n",
    "                        f\"Session {session_number} covered various therapeutic topics and exchanges between \"\n",
    "                        f\"the therapist and {patient_profile['name']}. The discussion included exploration of \"\n",
    "                        f\"the patient's thoughts, feelings, and experiences. Several therapeutic techniques were \"\n",
    "                        f\"discussed and practiced during the session. The patient showed engagement with the \"\n",
    "                        f\"therapeutic process and the therapist provided appropriate guidance and support throughout \"\n",
    "                        f\"the session. Key themes included mental health management and coping strategies.\"\n",
    "                    )\n",
    "                    return \"Session Summary:\\n\\n\" + fallback_summary\n",
    "                logging.warning(f\"Invalid summary generated (attempt {attempt + 1}), retrying...\")\n",
    "                continue\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating session summary: {e}\")\n",
    "            if attempt == max_attempts - 1:\n",
    "                fallback_summary = (\n",
    "                    f\"Session {session_number} covered various therapeutic topics and exchanges between \"\n",
    "                    f\"the therapist and {patient_profile['name']}. The discussion included exploration of \"\n",
    "                    f\"the patient's thoughts, feelings, and experiences. Several therapeutic techniques were \"\n",
    "                    f\"discussed and practiced during the session. The patient showed engagement with the \"\n",
    "                    f\"therapeutic process and the therapist provided appropriate guidance and support throughout \"\n",
    "                    f\"the session. Key themes included mental health management and coping strategies.\"\n",
    "                )\n",
    "                return \"Session Summary:\\n\\n\" + fallback_summary\n",
    "            continue\n",
    "\n",
    "def initialize_llama_model(num_instances=2):\n",
    "    \"\"\"\n",
    "    Initializes multiple instances of the LLaMA model for parallel processing.\n",
    "\n",
    "    Args:\n",
    "        num_instances (int): The number of model instances to initialize.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of initialized LLaMA model instances.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    for _ in range(num_instances):\n",
    "        model = Llama.from_pretrained(\n",
    "            repo_id=\"bartowski/Mistral-7B-Instruct-v0.3-GGUF\",\n",
    "            filename=\"Mistral-7B-Instruct-v0.3-Q8_0.gguf\",\n",
    "            verbose=False,\n",
    "            temperature=1,\n",
    "            repeat_penalty=1.1,\n",
    "            top_k=40,\n",
    "            top_p=0.95,\n",
    "            min_p=0.05,\n",
    "            n_ctx=10000,\n",
    "            n_batch=10000,\n",
    "            n_gpu_layers=35,\n",
    "            offload_kqv=True,\n",
    "            f16_kv=True,\n",
    "            stop=STOP_TOKENS,\n",
    "            max_tokens=600,\n",
    "        )\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def conduct_session(patient_profile, session_number, previous_summary, model):\n",
    "    \"\"\"\n",
    "    Conducts a single therapy session with enhanced error handling and detailed termination logging.\n",
    "\n",
    "    Args:\n",
    "        patient_profile (dict): The profile of the patient.\n",
    "        session_number (int): The current session number.\n",
    "        previous_summary (str): Summary of the previous session.\n",
    "        model: The language model to generate responses.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: The full conversation and the session summary.\n",
    "    \"\"\"\n",
    "    conversation_history = []\n",
    "    summary_conversation_history = []\n",
    "    full_conversation = f\"Session Number: {session_number}\\n\\n\"\n",
    "    turn_count = 0\n",
    "    word_count = 0\n",
    "    last_therapist_message = \"\"\n",
    "    termination_reason = None\n",
    "    termination_details = None\n",
    "\n",
    "    try:\n",
    "        max_retries = 10\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                patient_message = generate_patient_response(\n",
    "                    conversation_history,\n",
    "                    patient_profile,\n",
    "                    session_number,\n",
    "                    previous_summary,\n",
    "                    is_first_message=True\n",
    "                )\n",
    "                if patient_message:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                logging.warning(f\"Attempt {attempt + 1} failed for initial patient message: {e}\")\n",
    "                time.sleep(2)\n",
    "\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": patient_message})\n",
    "        full_conversation += f\"Patient: {patient_message}\\n\\n\"\n",
    "        turn_count += 1\n",
    "        word_count += count_words(patient_message)\n",
    "\n",
    "        while turn_count < 50 and word_count < 5000:\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    cbt_response = get_cbt_response(conversation_history, model)\n",
    "                    if cbt_response:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise\n",
    "                    logging.warning(f\"Attempt {attempt + 1} failed for CBT response: {e}\")\n",
    "                    time.sleep(2)\n",
    "\n",
    "            conversation_history.append({\"role\": \"assistant\", \"content\": cbt_response})\n",
    "            if turn_count < 48:\n",
    "                summary_conversation_history.append({\"role\": \"assistant\", \"content\": cbt_response})\n",
    "            full_conversation += f\"Therapist: {cbt_response}\\n\\n\"\n",
    "            turn_count += 1\n",
    "            word_count += count_words(cbt_response)\n",
    "            last_therapist_message = cbt_response\n",
    "\n",
    "            session_end, end_phrase = detect_session_end(last_therapist_message)\n",
    "            if session_end:\n",
    "                termination_reason = \"Natural Session End\"\n",
    "                termination_details = f\"Detected end phrase: '{end_phrase}'\"\n",
    "                if summary_conversation_history and summary_conversation_history[-1][\"role\"] == \"assistant\":\n",
    "                    summary_conversation_history.pop()\n",
    "                logging.info(f\"Session {session_number} for {patient_profile['name']} terminated naturally with phrase: '{end_phrase}'\")\n",
    "                break\n",
    "\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    patient_message = generate_patient_response(\n",
    "                        conversation_history,\n",
    "                        patient_profile,\n",
    "                        session_number,\n",
    "                        previous_summary\n",
    "                    )\n",
    "                    if patient_message:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    if attempt == max_retries - 1:\n",
    "                        raise\n",
    "                    logging.warning(f\"Attempt {attempt + 1} failed for patient response: {e}\")\n",
    "                    time.sleep(2)\n",
    "\n",
    "            conversation_history.append({\"role\": \"user\", \"content\": patient_message})\n",
    "            summary_conversation_history.append({\"role\": \"user\", \"content\": patient_message})\n",
    "            full_conversation += f\"Patient: {patient_message}\\n\\n\"\n",
    "            turn_count += 1\n",
    "            word_count += count_words(patient_message)\n",
    "\n",
    "            if word_count >= 5000:\n",
    "                termination_reason = \"Word Limit Exceeded\"\n",
    "                termination_details = f\"Word count: {word_count}/5000\"\n",
    "                logging.info(f\"Session {session_number} for {patient_profile['name']} terminated due to word limit: {word_count} words\")\n",
    "                full_conversation += f\"****Session Terminated: {termination_reason} - {termination_details}****\\n\"\n",
    "                break\n",
    "\n",
    "        if turn_count >= 50:\n",
    "            termination_reason = \"Turn Limit Exceeded\"\n",
    "            termination_details = f\"Turn count: {turn_count}/50\"\n",
    "            if summary_conversation_history and summary_conversation_history[-1][\"role\"] == \"assistant\":\n",
    "                summary_conversation_history.pop()\n",
    "            logging.info(f\"Session {session_number} for {patient_profile['name']} terminated due to turn limit: {turn_count} turns\")\n",
    "            full_conversation += f\"****Session Terminated: {termination_reason} - {termination_details}****\\n\"\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                session_summary = generate_session_summary(summary_conversation_history, patient_profile, session_number)\n",
    "                if session_summary:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                logging.warning(f\"Attempt {attempt + 1} failed for session summary: {e}\")\n",
    "                time.sleep(2)\n",
    "\n",
    "        if termination_reason:\n",
    "            full_conversation += f\"\\nTermination Details:\\n\"\n",
    "            full_conversation += f\"Reason: {termination_reason}\\n\"\n",
    "            full_conversation += f\"Details: {termination_details}\\n\\n\"\n",
    "\n",
    "        full_conversation += f\"\\n{session_summary}\\n\"\n",
    "\n",
    "        logging.info(f\"Session {session_number} completed for {patient_profile['name']}:\")\n",
    "        logging.info(f\"- Total turns: {turn_count}\")\n",
    "        logging.info(f\"- Total words: {word_count}\")\n",
    "        logging.info(f\"- Termination reason: {termination_reason}\")\n",
    "        logging.info(f\"- Termination details: {termination_details}\")\n",
    "\n",
    "        return full_conversation, session_summary\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Critical error in session {session_number} for {patient_profile['name']}: {str(e)}\"\n",
    "        logging.error(error_msg)\n",
    "        if full_conversation:\n",
    "            termination_reason = \"Critical Error\"\n",
    "            termination_details = str(e)\n",
    "            error_conversation = full_conversation + f\"\\nTermination Details:\\n\"\n",
    "            error_conversation += f\"Reason: {termination_reason}\\n\"\n",
    "            error_conversation += f\"Details: {termination_details}\\n\"\n",
    "            return error_conversation, f\"Session terminated due to error: {str(e)}\"\n",
    "        raise\n",
    "\n",
    "def conduct_therapy_course(patient_profile, model):\n",
    "    \"\"\"\n",
    "    Conducts a full course of therapy sessions for a patient.\n",
    "\n",
    "    Args:\n",
    "        patient_profile (dict): The profile of the patient.\n",
    "        model: The language model to generate responses.\n",
    "    \"\"\"\n",
    "    output_dir = f\"CBT_Depression_Simulations_{patient_profile['name']}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    num_sessions = 20\n",
    "    previous_summary = None\n",
    "\n",
    "    for session_number in range(1, num_sessions + 1):\n",
    "        logging.info(f\"Starting session {session_number} for {patient_profile['name']}\")\n",
    "        try:\n",
    "            conversation, session_summary = conduct_session(patient_profile, session_number, previous_summary, model)\n",
    "\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"session_{session_number}_{timestamp}.txt\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "            with open(filepath, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(conversation)\n",
    "            logging.info(f\"Session {session_number} for {patient_profile['name']} saved to: {filepath}\")\n",
    "\n",
    "            previous_summary = session_summary\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in session {session_number} for {patient_profile['name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "def conduct_parallel_sessions(patient_profiles, num_concurrent=2):\n",
    "    \"\"\"\n",
    "    Conducts therapy sessions for multiple patients in parallel.\n",
    "\n",
    "    Args:\n",
    "        patient_profiles (list): A list of patient profiles.\n",
    "        num_concurrent (int): The number of concurrent sessions to run.\n",
    "    \"\"\"\n",
    "    models = initialize_llama_model(num_concurrent)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_concurrent) as executor:\n",
    "        futures = []\n",
    "        for i, profile in enumerate(patient_profiles[:num_concurrent]):\n",
    "            futures.append(\n",
    "                executor.submit(conduct_therapy_course, profile, models[i])\n",
    "            )\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing patients\"):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in parallel session: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the CBT simulation for all patient profiles.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        available_vram = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        batch_size = max(1, min(3, int(available_vram / 15)))\n",
    "    except:\n",
    "        batch_size = 2\n",
    "\n",
    "    logging.info(f\"Using batch size of {batch_size} for parallel processing\")\n",
    "\n",
    "    for i in range(0, len(patient_profiles), batch_size):\n",
    "        batch = patient_profiles[i:i+batch_size]\n",
    "        conduct_parallel_sessions(batch, num_concurrent=batch_size)\n",
    "        if i + batch_size < len(patient_profiles):\n",
    "            time.sleep(30)\n",
    "\n",
    "    logging.info(\"All CBT simulations completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    models = initialize_llama_model(2)\n",
    "    verify_gpu_setup()\n",
    "\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
